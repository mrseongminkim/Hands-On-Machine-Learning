{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000, validate on 5000 samples\n",
      "Epoch 1, loss: 1.1316502030121858, accuracy: 0.6232727272727273 val_loss: 0.6769441383279813, val_accuracy: 0.757\n",
      "Epoch 2, loss: 0.6036612820476207, accuracy: 0.7859636363636363 val_loss: 0.5395136046561466, val_accuracy: 0.8142\n",
      "Epoch 3, loss: 0.514902888818353, accuracy: 0.8193272727272727 val_loss: 0.48102845640698816, val_accuracy: 0.833\n",
      "Epoch 4, loss: 0.473003404580139, accuracy: 0.8340727272727273 val_loss: 0.44933794884924677, val_accuracy: 0.8426\n",
      "Epoch 5, loss: 0.44927452446122446, accuracy: 0.8424363636363636 val_loss: 0.4314402946431166, val_accuracy: 0.8496\n",
      "Epoch 6, loss: 0.42828405559617744, accuracy: 0.8492363636363637 val_loss: 0.4392118185378943, val_accuracy: 0.8448\n",
      "Epoch 7, loss: 0.41242473550821335, accuracy: 0.8559636363636364 val_loss: 0.40767952012028663, val_accuracy: 0.8602\n",
      "Epoch 8, loss: 0.39993671059105684, accuracy: 0.8597090909090909 val_loss: 0.4008289171252281, val_accuracy: 0.8578\n",
      "Epoch 9, loss: 0.3878830282397919, accuracy: 0.8625090909090909 val_loss: 0.3825543500055933, val_accuracy: 0.8628\n",
      "Epoch 10, loss: 0.3767412832053405, accuracy: 0.8671454545454546 val_loss: 0.3664042287666327, val_accuracy: 0.8724\n",
      "Epoch 11, loss: 0.3671952869489555, accuracy: 0.8706363636363637 val_loss: 0.38179193626923164, val_accuracy: 0.8662\n",
      "Epoch 12, loss: 0.35847410430493504, accuracy: 0.8726545454545455 val_loss: 0.3686119589930887, val_accuracy: 0.8714\n",
      "Epoch 13, loss: 0.3500696529372616, accuracy: 0.8763090909090909 val_loss: 0.3542822783658649, val_accuracy: 0.8756\n",
      "Epoch 14, loss: 0.3416565905209715, accuracy: 0.8784727272727273 val_loss: 0.3512074028135865, val_accuracy: 0.8746\n",
      "Epoch 15, loss: 0.3342287845350477, accuracy: 0.8797454545454545 val_loss: 0.3460115406448674, val_accuracy: 0.876\n",
      "Epoch 16, loss: 0.3278769067964837, accuracy: 0.882 val_loss: 0.3389518263328607, val_accuracy: 0.8748\n",
      "Epoch 17, loss: 0.32086345871098865, accuracy: 0.8840727272727272 val_loss: 0.34679560669383425, val_accuracy: 0.8798\n",
      "Epoch 18, loss: 0.31338468821607685, accuracy: 0.8866545454545455 val_loss: 0.3250933394168213, val_accuracy: 0.8804\n",
      "Epoch 19, loss: 0.30831855244678835, accuracy: 0.8896545454545455 val_loss: 0.32995290717311726, val_accuracy: 0.8806\n",
      "Epoch 20, loss: 0.3027069821667713, accuracy: 0.8904545454545455 val_loss: 0.33250608594174597, val_accuracy: 0.877\n",
      "Epoch 21, loss: 0.296648553463697, accuracy: 0.8930545454545454 val_loss: 0.3365285367153253, val_accuracy: 0.8804\n",
      "Epoch 22, loss: 0.2914559798940383, accuracy: 0.8946727272727273 val_loss: 0.34031274051043636, val_accuracy: 0.8772\n",
      "Epoch 23, loss: 0.28691059147474235, accuracy: 0.8961454545454546 val_loss: 0.31755543777802187, val_accuracy: 0.8826\n",
      "Epoch 24, loss: 0.28097718000117256, accuracy: 0.8994 val_loss: 0.31055504985296045, val_accuracy: 0.8868\n",
      "Epoch 25, loss: 0.27768795264406976, accuracy: 0.8992363636363636 val_loss: 0.32308961161572464, val_accuracy: 0.883\n",
      "Epoch 26, loss: 0.2729846527101066, accuracy: 0.9020727272727272 val_loss: 0.32099248435656735, val_accuracy: 0.879\n",
      "Epoch 27, loss: 0.2679992013433737, accuracy: 0.9022363636363636 val_loss: 0.3206080008701534, val_accuracy: 0.8804\n",
      "Epoch 28, loss: 0.2643341199538783, accuracy: 0.9048363636363637 val_loss: 0.3051338158547878, val_accuracy: 0.8908\n",
      "Epoch 29, loss: 0.25932971499491875, accuracy: 0.9063636363636364 val_loss: 0.3167837270221133, val_accuracy: 0.8876\n",
      "Epoch 30, loss: 0.2562146474395452, accuracy: 0.9067818181818181 val_loss: 0.31240138852862037, val_accuracy: 0.889\n",
      "test_loss: 0.34890136491662016, test_accuracy: 0.8762\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "NUM_EPOCHS = 30\n",
    "VALID_DATA_SIZE = 5_000\n",
    "CLASS_NAMES = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "train_data = datasets.FashionMNIST(\"./\", download=True, train=True, transform=transforms.ToTensor())\n",
    "test_data = datasets.FashionMNIST(\"./\", download=True, train=False, transform=transforms.ToTensor())\n",
    "\n",
    "valid_set = Subset(train_data, torch.arange(VALID_DATA_SIZE))\n",
    "train_set = Subset(train_data, torch.arange(VALID_DATA_SIZE, len(train_data)))\n",
    "\n",
    "train = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "valid = DataLoader(valid_set, batch_size=32, shuffle=True)\n",
    "test = DataLoader(test_data, batch_size=32, shuffle=True)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(28 * 28, 300),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(300, 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 10)\n",
    ").cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "print(f\"Train on {len(train_data) - VALID_DATA_SIZE}, validate on {VALID_DATA_SIZE} samples\")\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    total_loss = 0\n",
    "    accuracy = 0\n",
    "    for datas, labels in train:\n",
    "        datas = datas.cuda()\n",
    "        labels = labels.cuda()\n",
    "        result: torch.Tensor = model(datas)\n",
    "        answer = result.argmax(dim=1)\n",
    "        correct = torch.sum(answer == labels)\n",
    "        loss: torch.Tensor = criterion(result, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        accuracy += correct.item()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch + 1}, loss: {total_loss / len(train)}, accuracy: {accuracy / len(train_set)}\", end=' ')\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        accuracy = 0\n",
    "        for datas, labels in valid:\n",
    "            datas = datas.cuda()\n",
    "            labels = labels.cuda()\n",
    "            result: torch.Tensor = model(datas)\n",
    "            answer = result.argmax(dim=1)\n",
    "            correct = torch.sum(answer == labels)\n",
    "            loss: torch.Tensor = criterion(result, labels)\n",
    "            accuracy += correct.item()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"val_loss: {total_loss / len(valid)}, val_accuracy: {accuracy / len(valid_set)}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    accuracy = 0\n",
    "    for datas, labels in test:\n",
    "        datas = datas.cuda()\n",
    "        labels = labels.cuda()\n",
    "        result: torch.Tensor = model(datas)\n",
    "        answer = result.argmax(dim=1)\n",
    "        correct = torch.sum(answer == labels)\n",
    "        loss: torch.Tensor = criterion(result, labels)\n",
    "        accuracy += correct.item()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"test_loss: {total_loss / len(test)}, test_accuracy: {accuracy / len(test_data)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
